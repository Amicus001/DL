{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Data File ==> DataFrame, Numpy (전처리) ==> Tensor ==> Dataset(피처 + 타겟) ==> DataLoader 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95f0a02e902c1f7c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset & DataLoader 살펴보기\n",
    "- Pytorch에서 배치크기만 데이터를 조절하기 위한 메카니즘\n",
    "- Dataset : 사용 데이터를 기반으로 사용자 정의 클래스 작성\n",
    "- DataLoader : 지정된 Dataset에서 지정된 batch size만큼 피처와 타겟을 추출하여 전달"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94be82110b73acc8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[1] 모듈로딩 및 데이터 준비"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5a98f8dec4fa3c7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### ===> 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.191081Z",
     "start_time": "2024-03-15T06:43:00.185490Z"
    }
   },
   "id": "63296d3d676f364",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "[2] 데이터셋 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a658d8f957c7648"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 사용자 정의 데이터셋 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5bbb7cb093c09c3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     sepal_length  sepal_width  petal_length  petal_width    variety\n0    sepal.length  sepal.width  petal.length  petal.width    variety\n1             5.1          3.5           1.4          0.2     Setosa\n2             4.9            3           1.4          0.2     Setosa\n3             4.7          3.2           1.3          0.2     Setosa\n4             4.6          3.1           1.5          0.2     Setosa\n..            ...          ...           ...          ...        ...\n146           6.7            3           5.2          2.3  Virginica\n147           6.3          2.5             5          1.9  Virginica\n148           6.5            3           5.2            2  Virginica\n149           6.2          3.4           5.4          2.3  Virginica\n150           5.9            3           5.1          1.8  Virginica\n\n[151 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>variety</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sepal.length</td>\n      <td>sepal.width</td>\n      <td>petal.length</td>\n      <td>petal.width</td>\n      <td>variety</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.9</td>\n      <td>3</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.7</td>\n      <td>3</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>Virginica</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5</td>\n      <td>1.9</td>\n      <td>Virginica</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.5</td>\n      <td>3</td>\n      <td>5.2</td>\n      <td>2</td>\n      <td>Virginica</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>Virginica</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>5.9</td>\n      <td>3</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>Virginica</td>\n    </tr>\n  </tbody>\n</table>\n<p>151 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../datas/iris.csv'\n",
    "irisDF = pd.read_csv(file, header = None)\n",
    "irisDF.columns = ['sepal_length', 'sepal_width', 'petal_length','petal_width','variety']\n",
    "irisDF"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.301152Z",
     "start_time": "2024-03-15T06:43:00.284391Z"
    }
   },
   "id": "661ddd67ddb4fa3b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2],\n       [5.4, 3.9, 1.7, 0.4],\n       [4.6, 3.4, 1.4, 0.3],\n       [5. , 3.4, 1.5, 0.2],\n       [4.4, 2.9, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.1],\n       [5.4, 3.7, 1.5, 0.2],\n       [4.8, 3.4, 1.6, 0.2],\n       [4.8, 3. , 1.4, 0.1],\n       [4.3, 3. , 1.1, 0.1],\n       [5.8, 4. , 1.2, 0.2],\n       [5.7, 4.4, 1.5, 0.4],\n       [5.4, 3.9, 1.3, 0.4],\n       [5.1, 3.5, 1.4, 0.3],\n       [5.7, 3.8, 1.7, 0.3],\n       [5.1, 3.8, 1.5, 0.3],\n       [5.4, 3.4, 1.7, 0.2],\n       [5.1, 3.7, 1.5, 0.4],\n       [4.6, 3.6, 1. , 0.2],\n       [5.1, 3.3, 1.7, 0.5],\n       [4.8, 3.4, 1.9, 0.2],\n       [5. , 3. , 1.6, 0.2],\n       [5. , 3.4, 1.6, 0.4],\n       [5.2, 3.5, 1.5, 0.2],\n       [5.2, 3.4, 1.4, 0.2],\n       [4.7, 3.2, 1.6, 0.2],\n       [4.8, 3.1, 1.6, 0.2],\n       [5.4, 3.4, 1.5, 0.4],\n       [5.2, 4.1, 1.5, 0.1],\n       [5.5, 4.2, 1.4, 0.2],\n       [4.9, 3.1, 1.5, 0.2],\n       [5. , 3.2, 1.2, 0.2],\n       [5.5, 3.5, 1.3, 0.2],\n       [4.9, 3.6, 1.4, 0.1],\n       [4.4, 3. , 1.3, 0.2],\n       [5.1, 3.4, 1.5, 0.2],\n       [5. , 3.5, 1.3, 0.3],\n       [4.5, 2.3, 1.3, 0.3],\n       [4.4, 3.2, 1.3, 0.2],\n       [5. , 3.5, 1.6, 0.6],\n       [5.1, 3.8, 1.9, 0.4],\n       [4.8, 3. , 1.4, 0.3],\n       [5.1, 3.8, 1.6, 0.2],\n       [4.6, 3.2, 1.4, 0.2],\n       [5.3, 3.7, 1.5, 0.2],\n       [5. , 3.3, 1.4, 0.2],\n       [7. , 3.2, 4.7, 1.4],\n       [6.4, 3.2, 4.5, 1.5],\n       [6.9, 3.1, 4.9, 1.5],\n       [5.5, 2.3, 4. , 1.3],\n       [6.5, 2.8, 4.6, 1.5],\n       [5.7, 2.8, 4.5, 1.3],\n       [6.3, 3.3, 4.7, 1.6],\n       [4.9, 2.4, 3.3, 1. ],\n       [6.6, 2.9, 4.6, 1.3],\n       [5.2, 2.7, 3.9, 1.4],\n       [5. , 2. , 3.5, 1. ],\n       [5.9, 3. , 4.2, 1.5],\n       [6. , 2.2, 4. , 1. ],\n       [6.1, 2.9, 4.7, 1.4],\n       [5.6, 2.9, 3.6, 1.3],\n       [6.7, 3.1, 4.4, 1.4],\n       [5.6, 3. , 4.5, 1.5],\n       [5.8, 2.7, 4.1, 1. ],\n       [6.2, 2.2, 4.5, 1.5],\n       [5.6, 2.5, 3.9, 1.1],\n       [5.9, 3.2, 4.8, 1.8],\n       [6.1, 2.8, 4. , 1.3],\n       [6.3, 2.5, 4.9, 1.5],\n       [6.1, 2.8, 4.7, 1.2],\n       [6.4, 2.9, 4.3, 1.3],\n       [6.6, 3. , 4.4, 1.4],\n       [6.8, 2.8, 4.8, 1.4],\n       [6.7, 3. , 5. , 1.7],\n       [6. , 2.9, 4.5, 1.5],\n       [5.7, 2.6, 3.5, 1. ],\n       [5.5, 2.4, 3.8, 1.1],\n       [5.5, 2.4, 3.7, 1. ],\n       [5.8, 2.7, 3.9, 1.2],\n       [6. , 2.7, 5.1, 1.6],\n       [5.4, 3. , 4.5, 1.5],\n       [6. , 3.4, 4.5, 1.6],\n       [6.7, 3.1, 4.7, 1.5],\n       [6.3, 2.3, 4.4, 1.3],\n       [5.6, 3. , 4.1, 1.3],\n       [5.5, 2.5, 4. , 1.3],\n       [5.5, 2.6, 4.4, 1.2],\n       [6.1, 3. , 4.6, 1.4],\n       [5.8, 2.6, 4. , 1.2],\n       [5. , 2.3, 3.3, 1. ],\n       [5.6, 2.7, 4.2, 1.3],\n       [5.7, 3. , 4.2, 1.2],\n       [5.7, 2.9, 4.2, 1.3],\n       [6.2, 2.9, 4.3, 1.3],\n       [5.1, 2.5, 3. , 1.1],\n       [5.7, 2.8, 4.1, 1.3],\n       [6.3, 3.3, 6. , 2.5],\n       [5.8, 2.7, 5.1, 1.9],\n       [7.1, 3. , 5.9, 2.1],\n       [6.3, 2.9, 5.6, 1.8],\n       [6.5, 3. , 5.8, 2.2],\n       [7.6, 3. , 6.6, 2.1],\n       [4.9, 2.5, 4.5, 1.7],\n       [7.3, 2.9, 6.3, 1.8],\n       [6.7, 2.5, 5.8, 1.8],\n       [7.2, 3.6, 6.1, 2.5],\n       [6.5, 3.2, 5.1, 2. ],\n       [6.4, 2.7, 5.3, 1.9],\n       [6.8, 3. , 5.5, 2.1],\n       [5.7, 2.5, 5. , 2. ],\n       [5.8, 2.8, 5.1, 2.4],\n       [6.4, 3.2, 5.3, 2.3],\n       [6.5, 3. , 5.5, 1.8],\n       [7.7, 3.8, 6.7, 2.2],\n       [7.7, 2.6, 6.9, 2.3],\n       [6. , 2.2, 5. , 1.5],\n       [6.9, 3.2, 5.7, 2.3],\n       [5.6, 2.8, 4.9, 2. ],\n       [7.7, 2.8, 6.7, 2. ],\n       [6.3, 2.7, 4.9, 1.8],\n       [6.7, 3.3, 5.7, 2.1],\n       [7.2, 3.2, 6. , 1.8],\n       [6.2, 2.8, 4.8, 1.8],\n       [6.1, 3. , 4.9, 1.8],\n       [6.4, 2.8, 5.6, 2.1],\n       [7.2, 3. , 5.8, 1.6],\n       [7.4, 2.8, 6.1, 1.9],\n       [7.9, 3.8, 6.4, 2. ],\n       [6.4, 2.8, 5.6, 2.2],\n       [6.3, 2.8, 5.1, 1.5],\n       [6.1, 2.6, 5.6, 1.4],\n       [7.7, 3. , 6.1, 2.3],\n       [6.3, 3.4, 5.6, 2.4],\n       [6.4, 3.1, 5.5, 1.8],\n       [6. , 3. , 4.8, 1.8],\n       [6.9, 3.1, 5.4, 2.1],\n       [6.7, 3.1, 5.6, 2.4],\n       [6.9, 3.1, 5.1, 2.3],\n       [5.8, 2.7, 5.1, 1.9],\n       [6.8, 3.2, 5.9, 2.3],\n       [6.7, 3.3, 5.7, 2.5],\n       [6.7, 3. , 5.2, 2.3],\n       [6.3, 2.5, 5. , 1.9],\n       [6.5, 3. , 5.2, 2. ],\n       [6.2, 3.4, 5.4, 2.3],\n       [5.9, 3. , 5.1, 1.8]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisNP = np.loadtxt(file, delimiter = ',', usecols = [0,1,2,3],skiprows= 1)\n",
    "irisNP"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.332388Z",
     "start_time": "2024-03-15T06:43:00.309106Z"
    }
   },
   "id": "98b6737cceaae48d",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(pandas.core.frame.DataFrame, numpy.ndarray, 'DataFrame', 'ndarray')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 타입 체크\n",
    "type(irisDF), type(irisNP), irisDF.__class__.__name__, irisNP.__class__.__name__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.347611Z",
     "start_time": "2024-03-15T06:43:00.334382Z"
    }
   },
   "id": "50f01f46729f3e68",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF\n"
     ]
    }
   ],
   "source": [
    "if irisDF.__class__.__name__ == 'DataFrame' :\n",
    "    print('DF')\n",
    "else:\n",
    "    print('-----')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.363702Z",
     "start_time": "2024-03-15T06:43:00.349606Z"
    }
   },
   "id": "91b69fbf81995d5",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(irisDF, pd.DataFrame), isinstance(irisNP, pd.DataFrame), isinstance(irisDF, np.ndarray),isinstance(irisNP, np.ndarray), sep = '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.409588Z",
     "start_time": "2024-03-15T06:43:00.402222Z"
    }
   },
   "id": "82621a52ce7d13b8",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### 사용자 정의 DataSet 클래스\n",
    "# - 데이터의 Tensor 변환\n",
    "\n",
    "class DLDataset(Dataset):\n",
    "    # 초기화 함수 콜백함수 (callback function)\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        \n",
    "        # x,y 데이터 ==> ndarray\n",
    "        x_data = x_data.values if isinstance(x_data, pd.DataFrame) else x_data\n",
    "        y_data = y_data.values if isinstance(y_data, pd.DataFrame) else y_data\n",
    "        # 넘파이면 그대로 ㄱㅊ    다만 데이터프레임이면 values만 뺴서 갖고오자능\n",
    "        \n",
    "        # ndarray ==> tensor\n",
    "        self.feature = torch.FloatTensor(x_data)\n",
    "        self.target = torch.LongTensor(y_data)         # 라벨 인코딩 형식으로 진행함 (원핫인코딩 ㄴㄴ)\n",
    "        \n",
    "    # 데이터셋의 개수 체크 함수 콜백함수 (callback function)\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    # 특정 인덱스 데이터 + 라벨 반환 콜백함수 (callback function)\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.456119Z",
     "start_time": "2024-03-15T06:43:00.446639Z"
    }
   },
   "id": "ad14171d414d9fa6",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (151, 4) , 2D\n",
      "targetDF => (151,) , 1D\n"
     ]
    }
   ],
   "source": [
    "## 피처와 라벨로 분리\n",
    "featureDF = irisDF[irisDF.columns[:-1]]\n",
    "targetDF = irisDF[irisDF.columns[-1]]\n",
    "\n",
    "print(f\"featureDF => {featureDF.shape} , {featureDF.ndim}D\")\n",
    "print(f\"targetDF => {targetDF.shape} , {targetDF.ndim}D\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.519045Z",
     "start_time": "2024-03-15T06:43:00.498275Z"
    }
   },
   "id": "99c975d38a8acdd8",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 1) 2\n"
     ]
    }
   ],
   "source": [
    "# object 타입 타겟 ===> int 타입 타겟 변환\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "targetNP = LabelEncoder().fit_transform(targetDF)\n",
    "targetNP = targetNP.reshape(-1,1)\n",
    "print(targetNP.shape, targetNP.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.534884Z",
     "start_time": "2024-03-15T06:43:00.522025Z"
    }
   },
   "id": "609c2d0d5e077efb",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 데이터셋 생성  ==> DF, NP\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m my_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mDLDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatureDF\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargetNP\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[14], line 15\u001B[0m, in \u001B[0;36mDLDataset.__init__\u001B[1;34m(self, x_data, y_data)\u001B[0m\n\u001B[0;32m     11\u001B[0m y_data \u001B[38;5;241m=\u001B[39m y_data\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(y_data, pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;28;01melse\u001B[39;00m y_data\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# 넘파이면 그대로 ㄱㅊ    다만 데이터프레임이면 values만 뺴서 갖고오자능\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# ndarray ==> tensor\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFloatTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mLongTensor(y_data)\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# 데이터셋 생성  ==> DF, NP\n",
    "my_dataset = DLDataset(featureDF, targetNP)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.596792Z",
     "start_time": "2024-03-15T06:43:00.555073Z"
    }
   },
   "id": "fd63f3c1611f19b1",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(my_dataset[0], featureDF.iloc[0], targetDF[0], sep = '\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-15T06:43:00.597788Z"
    }
   },
   "id": "559d6b61c1914ab7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor([3]))\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 생성 => NP, NP\n",
    "my_dataset2 = DLDataset(irisNP, targetNP)\n",
    "print(my_dataset2[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.643158Z",
     "start_time": "2024-03-15T06:43:00.633113Z"
    }
   },
   "id": "6a41b8cbd69172ef",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [2-3] 학습용, 검증용, 테스트용 Dataset <hr>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1886d2dcfbe828d9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDS => 106, validDS => 15, testDS => 30\n"
     ]
    }
   ],
   "source": [
    "### ===> 파이토치\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 학습용, 검증용, 테스트 데이터 비율\n",
    "seed = torch.Generator().manual_seed(2)\n",
    "\n",
    "trainDS, validDS, testDS = random_split(my_dataset2, [0.7, 0.1, 0.2], generator = seed )\n",
    "\n",
    "print(f\"trainDS => {len(trainDS)}, validDS => {len(validDS)}, testDS => {len(testDS)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.658830Z",
     "start_time": "2024-03-15T06:43:00.650291Z"
    }
   },
   "id": "afe809a48d7e356b",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 속성 =>\n",
      " indices: \n",
      " [81, 88, 133, 119, 141, 14, 53, 146, 20, 112, 10, 9, 78, 86, 28, 38, 80, 134, 127, 18, 8, 6, 41, 62, 105, 85, 121, 149, 34, 122, 65, 117, 11, 52, 100, 19, 24, 5, 114, 63, 37, 103, 68, 12, 102, 50, 77, 49, 150, 22, 79, 83, 107, 123, 98, 48, 29, 56, 137, 13, 67, 2, 120, 76, 130, 15, 115, 39, 87, 23, 84, 46, 25, 66, 60, 144, 94, 30, 90, 147, 26, 91, 72, 42, 3, 101, 113, 58, 73, 33, 92, 97, 54, 51, 69, 96, 128, 106, 139, 36, 116, 126, 118, 99, 125, 131] \n",
      " dataset : <__main__.DLDataset object at 0x00000131A97A6AF0>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Subset 속성 =>\\n indices: \\n {trainDS.indices} \\n dataset : {trainDS.dataset}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.689411Z",
     "start_time": "2024-03-15T06:43:00.683683Z"
    }
   },
   "id": "4123cb1ce27c7bb1",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 속성 =>\n",
      " indices: \n",
      " [111, 108, 47, 1, 0, 132, 70, 7, 61, 109, 148, 136, 140, 64, 135] \n",
      " dataset : <__main__.DLDataset object at 0x00000131A97A6AF0>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Subset 속성 =>\\n indices: \\n {validDS.indices} \\n dataset : {validDS.dataset}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.765938Z",
     "start_time": "2024-03-15T06:43:00.757404Z"
    }
   },
   "id": "d44fecf60518cb81",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "[3] DataLoader 생성 : 학습용, 검증용, 테스트용 <hr>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "635b35fae563d1fd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(11, 2, 3)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataLoader 생성\n",
    "# drop_last 매개변수 : 배치 사이즈로 데이터셋 분리 후 남는 데이터 처리 방법 설정 [기본 : False]\n",
    "batch = 10\n",
    "trainDL = DataLoader(trainDS, batch_size = batch)\n",
    "validDL = DataLoader(validDS, batch_size = batch)\n",
    "testDL = DataLoader(testDS, batch_size = batch)\n",
    "\n",
    "len(trainDL), len(validDL), len(testDL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.796932Z",
     "start_time": "2024-03-15T06:43:00.782453Z"
    }
   },
   "id": "9998b82a7727bb67",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 10\n",
      "trainDS => 106개, validDS => 15개, trainDS => 106개\n",
      "trainDL => 11개, validDL => 2개, testDL => 3개\n"
     ]
    }
   ],
   "source": [
    "# Epoch당 반복 단위\n",
    "print(f'batch_size : {batch}')\n",
    "print(f\"trainDS => {len(trainDS)}개, validDS => {len(validDS)}개, trainDS => {len(trainDS)}개\")\n",
    "print(f\"trainDL => {len(trainDL)}개, validDL => {len(validDL)}개, testDL => {len(testDL)}개\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.827306Z",
     "start_time": "2024-03-15T06:43:00.818420Z"
    }
   },
   "id": "14aabb7e7b795f73",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "[4] Model 클래스 정의 : 입/출력 피처수, 층 수, 은닉층의 노드수 <hr>\n",
    "- 구조설계\n",
    "    * 입력층 : 입력 <= 피처 갯수, iris 4개 \n",
    "    * 은닉층 : 마음대로 알아서 잘\n",
    "    * 출력층 : 출력 <= [분류] 타겟 클래스 갯수  [회귀] 1개"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c81ee0d14feca89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 모델 클래스 정의\n",
    "# 클래스명 : CModel\n",
    "\n",
    "class CModel(nn.Module):    # nn.Module을 상속받는다.\n",
    "    \n",
    "    # 모델 구성 요소 정의 함수\n",
    "    def __init__(self, in_, out_):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(in_, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_layer = nn.Linear(100, 27)\n",
    "        self.output_layer = nn.Linear(27, out_)\n",
    "        \n",
    "    # 순방향 학습 진행\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)            # W1x1 + W2x2 _ ... + Wnxn + b 반환\n",
    "        x = self.relu(x)                   # relu 함수 결과 100개 반환\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.857637Z",
     "start_time": "2024-03-15T06:43:00.840574Z"
    }
   },
   "id": "79f2872dbf54c5ee",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "[5] 학습 준비 : 실행 디바이스, 모델, 최적화, 손실함수, 학습 횟수, 학습 함수, 평가 함수, 예측 함수 <hr>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "213c7ba075564606"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 실행 디바이스 설정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 학습 횟수\n",
    "EPOCHS = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.873154Z",
     "start_time": "2024-03-15T06:43:00.858635Z"
    }
   },
   "id": "acef3389e569a499",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스\n",
    "IN, OUT = my_dataset2.feature.shape[1], len(np.unique(targetDF))\n",
    "print(IN, OUT)\n",
    "model = CModel(IN, OUT).to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:00.920050Z",
     "start_time": "2024-03-15T06:43:00.898406Z"
    }
   },
   "id": "9887a4904309f60b",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "LOSS_FN = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 최적화 인스턴스\n",
    "import torch.optim as optim\n",
    "OPTIMIZER = optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:02.124609Z",
     "start_time": "2024-03-15T06:43:00.922032Z"
    }
   },
   "id": "812dd61a9241f2dd",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 학습 및 검증 관련 함수 정의"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23e443d71865bba9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### ===> 학습 진행 함수\n",
    "def training():\n",
    "    # 학습 모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화\n",
    "    model.train()\n",
    "    \n",
    "    # 배치 크기만큼 학습 진행 및 저장\n",
    "    train_loss = []\n",
    "    for cnt, (feature, target) in enumerate(trainDL):\n",
    "        # print(cnt, feature, target)\n",
    "        # 배치 크기만큼의 학습 데이터 준비      \n",
    "        feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        target = target.squeeze()\n",
    "        \n",
    "        # 학습\n",
    "        pre_target = model(feature)\n",
    "        print(f\"pre_target => {pre_target.shape}, {pre_target.ndim}D\")\n",
    "        print(f\"target => {target.shape}, {target.ndim}D\")\n",
    "        \n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = LOSS_FN(pre_target, target)\n",
    "        train_loss.append(loss)\n",
    "        \n",
    "        # W, b 업데이트\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        \n",
    "        # 배치 단위 학습 진행 메시지 출력\n",
    "        print(f\"[Train {cnt} batch LOSS] ===> {loss}\")\n",
    "        \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    print(f\"[Train loss] ===> {loss}\")\n",
    "    \n",
    "    return train_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:02.139766Z",
     "start_time": "2024-03-15T06:43:02.126218Z"
    }
   },
   "id": "f143f4fcf13f0d0f",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### ===> 검증 및 평가 진행 함수\n",
    "def testing():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:02.154935Z",
     "start_time": "2024-03-15T06:43:02.142120Z"
    }
   },
   "id": "651690c6c7d95fc0",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### ===> 예측 함수\n",
    "def predict():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:02.170504Z",
     "start_time": "2024-03-15T06:43:02.156439Z"
    }
   },
   "id": "62690305bce44436",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "[6] 학습 진행 <hr>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "865e88b94c09240a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_target => torch.Size([10, 4]), 2D\n",
      "target => torch.Size([10]), 1D\n",
      "[Train 0 batch LOSS] ===> 1.3562825918197632\n",
      "pre_target => torch.Size([10, 4]), 2D\n",
      "target => torch.Size([10]), 1D\n",
      "[Train 1 batch LOSS] ===> 1.4004501104354858\n",
      "pre_target => torch.Size([10, 4]), 2D\n",
      "target => torch.Size([10]), 1D\n",
      "[Train 2 batch LOSS] ===> 1.307645559310913\n",
      "pre_target => torch.Size([10, 4]), 2D\n",
      "target => torch.Size([10]), 1D\n",
      "[Train 3 batch LOSS] ===> 1.3289483785629272\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 150 is out of bounds for dimension 0 with size 150",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m eps \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(EPOCHS):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# 학습\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# 검증\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# testing()\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00meps\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(train_loss)\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loss)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[28], line 8\u001B[0m, in \u001B[0;36mtraining\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# 배치 크기만큼 학습 진행 및 저장\u001B[39;00m\n\u001B[0;32m      7\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cnt, (feature, target) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(trainDL):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# print(cnt, feature, target)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# 배치 크기만큼의 학습 데이터 준비      \u001B[39;00m\n\u001B[0;32m     11\u001B[0m     feature, target \u001B[38;5;241m=\u001B[39m feature\u001B[38;5;241m.\u001B[39mto(DEVICE), target\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[0;32m     13\u001B[0m     target \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39msqueeze()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Pytorch38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "Cell \u001B[1;32mIn[14], line 24\u001B[0m, in \u001B[0;36mDLDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget[index]\n",
      "\u001B[1;31mIndexError\u001B[0m: index 150 is out of bounds for dimension 0 with size 150"
     ]
    }
   ],
   "source": [
    "for eps in range(EPOCHS):\n",
    "    # 학습\n",
    "    train_loss = training()\n",
    "    \n",
    "    # 검증\n",
    "    # testing()\n",
    "    \n",
    "    print(f\"[{eps}/{EPOCHS}] {sum(train_loss)/len(train_loss)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T06:43:02.651866Z",
     "start_time": "2024-03-15T06:43:02.172651Z"
    }
   },
   "id": "d887bd5f5668205d",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a1128f3a892d984f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-15T06:43:02.654858Z"
    }
   },
   "id": "f153209bd1b5284a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# DataLoader 속성\n",
    "for _ , (feature, target) in enumerate(trainDL):\n",
    "    print(f\"[{_}] feature {feature.shape}\")\n",
    "    ## 로더에서 가지고온 데이터만큼 학습 진행 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-15T06:43:02.656362Z"
    }
   },
   "id": "6dc46d1ccf12efab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb56344c182ae607",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
